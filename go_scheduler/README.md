# Внутреннее устройство планировщика задач (Go)

## Ключевая идея

- Не давать в руки программистам потоки
- Делать вид, что потоков нет, есть только горутины
- Абстрагировать всю сложность распределения горутин в рантайме

> **Рантайм (Cреда исполнения)**: вычислительное окружение, необходимое для выполнения компьютерной программы и доступное во время выполнения компьютерной программы.


## Модели

### `N-1 модель`

- Выполняем N горутин на одном потоке. Отношение один ко многим

**Как и когда будем вытеснять горутины?**

Компилятор добавит места в исходный код для переключения контекста.

- Например в момент проверки необходимого пространства для стека горутин (кооперативная многозадачность). Вся сложность переключения (context-swithing) горутин, остается на уровне рантайма.

> **Как быть с многоядерными процессорами?**

---

### `N-M модель`

- Выполняем N горутин на M потоках. Отношение многое ко многим

Не особо масштабируемый подход, так как необходима синхронизация между потоками, так как очередь всего одна.

- Синхронизация на основе **mutual exclusion**. Логика будет работать плохо (медленно) из-за большого количества вхождений в очередь и большого количества потоков.

> **Что если использовать lock-free конструкции?**

- Сихнронизация на основе атомарных переменных. Это будет лучше чем но подход с mutex, но **cache contention** никто не отменял.

> Когда ядро процессора обновляет значение, оно сбрасывает кеш для этого адреса в памяти для всех остальных ядер и объявляет, что владеет актуальным значением для адреса. Следующее ядро, прежде чем обновить счётчик, сначала вычитывает это значение из кеша другого ядра. 

> Когда много ядер одновременно пытаются обновить счётчик, то каждое становится в очередь и ждёт инвалидацию и вычитывание из кеша. Операция, которая должна укладываться в константное время внезапно становится O(N) по количеству ядер. Это и есть **cache contention**.

---

> **Что если для каждого потока создать свою локальную очередь?**

---

### `GMP модель`

- **G** - Goroutine (то, что исполняем)
- **M** - Machine (то, где исполняем)
- **P** - Processor (то, что управляет правами и ресурсами для исполнения)

Создаем для каждого потока отдельную локальную очередь (LRQ), это позволит минимизировать необходимость сихнронизировать данные между потоками.

> В планировщике Go есть две разные очереди выполнения: глобальная очередь выполнения (Global Run Queue - GRQ) и локальная очередь выполнения (Local Run Queue - LRQ)

> Размер локальной очереди ограничен и равен 256 задач (горутин)

> **В какую из очередей добавлять новую горутину?**

Если, в рамках этого потока, создается еще одна горутина, то 
она будет добавлена в эту же локальную очередь (LRQ)

> **Что делать, если в очередь закончатся горутины?**

- Есть две концепции:

1) **Work sharing**

Концепция, когда потоки делятся некоторыми горутинами между потоками.

Если у одного из потоков закончились задачи, то иногда некоторые потоки будут разделять свои горутины и отдавать на исполнение простаивающему потоку.

> **Как понять, когда нужно делиться задачами?**

Для данной задачи больше подходит вторая концепция

2) **Work Stealing**

Концепция в том, что потоки не будут периодически делиться задачами. "Нуждающиеся" в задачах потоки будут ходить в другие локальные очереди (LRQ) и брать задачи оттуда.

Из-за того, что "нуждающиеся потоки" будут ходить с чужие локальные очереди, значит нам нужна синхронизация.

Можно предположить, что такая ситуация будет происходить не очень часто. Поэтому это будет не очень критично.

Выбирая способ синхронизации, выбор склоняется в сторону **lock-free**. Так как это быстрее чем использование взаимного исключения.

> **У какой именно очереди "красть" задачи?**

- Выбираем очередь рандомно

> **Что делать, если в другой очереди тоже нет горутин?**

- Пробуем украсть четыре раза

> **Сколько задач забирать?**

- Забираем половину задач из другой локальной очереди

Брать мало задач неэффективно. Частые переходы между очередями приводят к конфликтам в кэше (cache contention), что снижает производительность.

## System calls в планировщике Go

**Handoff** — механизм в Go (Golang), который переназначает поток (M) другому потоку (M), если текущий M заблокировался системным вызовом (syscall). Это необходимо, чтобы работа горутин (G) не простаивала, пока текущий M ожидает ответа от cистемного вызова.

Планировщик Go сразу открепит поток (M) от процессора (P), если понимает, что поток будет заблокировани на системном вызове в течении долгого времени.

- В других случаях (short-lived syscalls) он позволит потоку быть заблокированным и не будет откреплять от процессора.

---

В планировщике Go (в рантайме языка) есть системный поток (**sysmon**). Это фоновый поток, который выполняет служебные задачи Go Runtime, не выполняет горутины, а следит за состоянием системы и работой приложения. 

> **Куда девать горутину после выполнения syscall-a?**

Добавляем горутину в очередь того процессора где она была. Если процесор недоступен (заполнена локальная очередь или поток связанный с процессором выполняет syscall), то ищем другую очередь

Если не нашли доступного процессора, то горутина добавляется в глобальную очередь.

## Очереди

> **Как быть с горутинами в глобальной очереди?**

На 61 вызов `runtime.schedule` в случае если у потока нет задач, и не получилось забрать задачу из другой локальной очереди, то задача будет выделена из глобальной очереди.

## Примитивы синхронизации

Горутина выполняется в системном потоке, поэтому стандартные механизмы синхронизации здесь не подходят. Если заблокировать горутину, это приведет к блокировке всего потока. Вместо этого лучше блокировать саму горутину. В момент блокировки она будет вытеснена и заменена другой горутиной в этом потоке.

**Нужны свои примитивы синхронизации**

### Cостояние горутины

- Running - выполняется в текущий момент
- Runnable - готова к выполнению
- Waiting - ожидает чего-либо (заблокирована на мьютексе или ждет завершение определенного syscall)

> **Куда делать горутины которые находятся в состоянии Waiting?**

**Wait queue** — термин, который в контексте планировщика Go (Go Scheduler) означает очередь для горутин (Goroutines), которые заблокированы и не могут быть запущены.

Принцип работы
Горутина переходит в состояние Waiting, если делает блокирующий вызов. Планировщик не создаёт отдельную очередь для Waiting-горутин, этим занимаются другие сущности. Например:

- Если горутина заблокирована из-за чтения или записи в канал, она попадает в Wait Queue этого канала, а уже оттуда — в глобальную очередь запуска (GRQ) и локальную очередь запуска (LRQ).

- Если горутина заблокирована из-за системного вызова, планировщик может создать новый поток операционной системы (M), чтобы продолжать выполнять другие горутины.

> **Не будут ли горутины голодать в этой очереди?**

- **Normal mode**

Когда горутина освобождает блокировку, она оповещает другую горутину в очереди ожидания, чтобы та взяла блокировку. Однако существует вероятность, что другая горутина, не из очереди ожидания, сделает это быстрее. В результате горутина из очереди ожидания была разбужена напрасно, и действия оказались бесполезными.

- **Starvation mode**

Когда горутина освобождает блокировку, она выбирает из очереди ожидания другую горутину, если та ждет дольше 1 миллисекунды. Это исключает возможность вставки отдельной горутины между unlock и lock. В результате гарантируется, что очередь ожидания не будет голодать.

## Циклы

> **Как быть с бесконечными циклами или CPU-bound задачами?**

Асинхронное вытеснение (asynchronous preemption) — это функция, которая позволяет прерывать долго выполняющиеся задачи, чтобы более равномерно распределять время работы между всеми задачами. 

Асинхронное вытеснение было введено в версии Go 1.14. Механизм срабатывает, когда задача выполняется более 10 мс, после чего специальный поток sysmon посылает сигнал текущему потоку (SIGURG), чтобы прервать выполняющуюся задачу.